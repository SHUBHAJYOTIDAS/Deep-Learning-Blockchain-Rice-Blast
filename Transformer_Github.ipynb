{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Add,Concatenate,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import  GlobalAveragePooling2D,Dropout,Conv2D,MaxPool2D,UpSampling2D,LeakyReLU,AveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import keras.backend as K\n",
    "from keras.layers import Layer\n",
    "!pip install patchify\n",
    "from patchify import patchify\n",
    "from tensorflow.keras.layers import Layer, Dense, Embedding, MultiHeadAttention\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a3539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_load= np.load(\"DATA/X_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf9bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load =np.load(\"DATA/X_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47142972",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=np.load(\"DATA/Y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070956eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=np.load(\"DATA/Y_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62288118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_load.shape)\n",
    "print(test_load.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2718a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "for i in tqdm(range(len(train_load))):\n",
    "    image=train_load[i]\n",
    "    patch_shape = (8, 8, 3)\n",
    "    patches = patchify(image, patch_shape, 8)\n",
    "    patches = np.reshape(patches, (784, 8, 8, 3))\n",
    "    p_f=Flatten()(patches)\n",
    "    train.append(p_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b15c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[]\n",
    "for j in tqdm(range(len(test_load))):\n",
    "    image_t=test_load[j]\n",
    "    patch_shape_t = (8, 8, 3)\n",
    "    patches_t = patchify(image_t, patch_shape_t, 8)\n",
    "    patches_t = np.reshape(patches_t, (784,8,8,3))\n",
    "    p=Flatten()(patches_t)\n",
    "    test.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=np.array(train)\n",
    "x2=np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bde61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=[]\n",
    "for i in range(len(Y_train)):\n",
    "    Y.append(int(Y_train[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_LABEL=[]\n",
    "for j in range(len(Y)):\n",
    "    if Y[j]==1:\n",
    "        FINAL_LABEL.append([1,0,0,0])\n",
    "    elif Y[j]==2:\n",
    "        FINAL_LABEL.append([0,1,0,0])\n",
    "    elif Y[j]==3:\n",
    "        FINAL_LABEL.append([0,0,1,0])\n",
    "    else:\n",
    "        FINAL_LABEL.append([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1=[]\n",
    "for i in range(len(Y_test)):\n",
    "    Y1.append(int(Y_test[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d3b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_LABEL_test=[]\n",
    "for j in range(len(Y1)):\n",
    "    if Y1[j]==1:\n",
    "        FINAL_LABEL_test.append([1,0,0,0])\n",
    "    elif Y1[j]==2:\n",
    "        FINAL_LABEL_test.append([0,1,0,0])\n",
    "    elif Y1[j]==3:\n",
    "        FINAL_LABEL_test.append([0,0,1,0])\n",
    "    else:\n",
    "        FINAL_LABEL_test.append([0,0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff956b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.array(FINAL_LABEL)\n",
    "y2=np.array(FINAL_LABEL_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7755bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(train))\n",
    "print(np.shape(test))\n",
    "print(y1.shape)\n",
    "print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302de1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassToken(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        w_init = tf.random_normal_initializer()\n",
    "        self.w = tf.Variable(\n",
    "            initial_value = w_init(shape=(1, 1, input_shape[-1]), dtype=tf.float32),\n",
    "            trainable = True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        hidden_dim = self.w.shape[-1]\n",
    "\n",
    "        cls = tf.broadcast_to(self.w, [batch_size, 1, hidden_dim])\n",
    "        cls = tf.cast(cls, dtype=inputs.dtype)\n",
    "        return cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8418325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, cf):\n",
    "    x = Dense(cf[\"mlp_dim\"], activation=\"gelu\")(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    x = Dense(cf[\"hidden_dim\"])(x)\n",
    "    x = Dropout(cf[\"dropout_rate\"])(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c7bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(x, cf):\n",
    "    skip_1 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = MultiHeadAttention(\n",
    "        num_heads=cf[\"num_heads\"], key_dim=cf[\"hidden_dim\"]\n",
    "    )(x, x)\n",
    "    x = Add()([x, skip_1])\n",
    "\n",
    "    skip_2 = x\n",
    "    x = LayerNormalization()(x)\n",
    "    x = mlp(x, cf)\n",
    "    x = Add()([x, skip_2])\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7712e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class selection_patches(Layer):\n",
    "    def __init__(self,input_shapes,**kwargs):\n",
    "        super(selection_patches,self).__init__(**kwargs)\n",
    "        self.input_shapes = input_shapes\n",
    "    def build(self,input_shape):\n",
    "        self.W1=self.add_weight(name='attention_weight1', shape=(192,1),\n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b1=self.add_weight(name='attention_bias1', shape=(1,),\n",
    "                               initializer='zeros', trainable=True)\n",
    "        self.W2=self.add_weight(name='attention_weight2', shape=(192,1),\n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b2=self.add_weight(name='attention_bias2', shape=(1,),\n",
    "                               initializer='zeros', trainable=True)\n",
    "        self.W3=self.add_weight(name='attention_weight3', shape=(192,1),\n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b3=self.add_weight(name='attention_bias3', shape=(1,),\n",
    "                               initializer='zeros', trainable=True)\n",
    "\n",
    "        self.W4=self.add_weight(name='attention_weight4', shape=(3,1),\n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b4=self.add_weight(name='attention_bias4', shape=(1,),\n",
    "                               initializer='zeros', trainable=True)\n",
    "        super(selection_patches, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e1 = K.relu(K.dot(x,self.W1)+self.b1)\n",
    "        e2 = K.relu(K.dot(x,self.W2)+self.b2)\n",
    "        e3 = K.relu(K.dot(x,self.W3)+self.b3)\n",
    "        e_head=tf.concat([e1, e2,e3],-1)\n",
    "        e = K.relu(K.dot(e_head,self.W4)+self.b4)\n",
    "        alpha = K.softmax(e)\n",
    "        #print(alpha)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        #print(\"After:\",alpha)\n",
    "        # Compute the context vector\n",
    "        #print(x)\n",
    "        batch_size = tf.shape(x)[0]\n",
    "        tensor1_shape = x.shape[1:]\n",
    "        #print(\"tensor1 shape:\",tensor1_shape)\n",
    "        tensor2_tiled = tf.tile(alpha, [1, 1, tensor1_shape[0], tensor1_shape[1]])\n",
    "        tensor1_reshaped = tf.reshape(x, [-1, 784, 1, 192])\n",
    "        #print(\"tensor2:\",tensor2_tiled )\n",
    "        context = tensor1_reshaped * tensor2_tiled\n",
    "        #print(\"CONTEXT:\",context)\n",
    "        context = K.sum(context, axis=1)\n",
    "\n",
    "        sorted_indices = tf.argsort(context, direction='DESCENDING', axis=-1)\n",
    "        top_64_indices = sorted_indices[:, :128]\n",
    "        #print(\"output:\",top_64_indices)\n",
    "        return top_64_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a7d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ViT(cf):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    input_shape = (784, cf[\"patch_size\"]*cf[\"patch_size\"]*cf[\"num_channels\"])\n",
    "    inputs = Input(input_shape)     ## (None, 256, 3072)\n",
    "    inputss=selection_patches(input_shapes=784)(inputs)\n",
    "    print(inputss)\n",
    "    \"\"\" Patch + Position Embeddings \"\"\"\n",
    "    patch_embed = Dense(cf[\"hidden_dim\"])(inputss)   ## (None, 256, 768)\n",
    "\n",
    "    positions = tf.range(start=0, limit=cf[\"num_patches\"], delta=1)\n",
    "    pos_embed = Embedding(input_dim=cf[\"num_patches\"], output_dim=cf[\"hidden_dim\"])(positions) ## (256, 768)\n",
    "    embed = patch_embed + pos_embed ## (None, 256, 768)\n",
    "\n",
    "    \"\"\" Adding Class Token \"\"\"\n",
    "    token = ClassToken()(embed)\n",
    "    x = Concatenate(axis=1)([token, embed]) ## (None, 257, 768)\n",
    "\n",
    "    for _ in range(cf[\"num_layers\"]):\n",
    "        x = transformer_encoder(x, cf)\n",
    "\n",
    "    \"\"\" Classification Head \"\"\"\n",
    "    x = LayerNormalization()(x)     ## (None, 257, 768)\n",
    "    x = x[:, 0, :]\n",
    "    x = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp={}\n",
    "hp[\"num_layers\"] = 12\n",
    "hp[\"hidden_dim\"] = 192\n",
    "# hp[\"mlp_dim\"] = 3072\n",
    "hp[\"mlp_dim\"] = 2048\n",
    "# hp[\"num_heads\"] = 12\n",
    "hp[\"num_heads\"] = 8\n",
    "hp[\"dropout_rate\"] = 0.1\n",
    "hp[\"image_size\"] = 224\n",
    "hp[\"num_channels\"] = 3\n",
    "hp[\"patch_size\"] = 8\n",
    "# hp[\"num_patches\"] = (hp[\"image_size\"]**2) // (hp[\"patch_size\"]**2)\n",
    "hp[\"num_patches\"] = 128\n",
    "hp[\"flat_patches_shape\"] = (hp[\"num_patches\"], hp[\"patch_size\"]*hp[\"patch_size\"]*hp[\"num_channels\"])\n",
    "print(hp[\"flat_patches_shape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8633370",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(hp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5224ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer='adam',\n",
    "        metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(\"high_acc.h5\", monitor='val_loss', verbose=1, save_best_only=True),\n",
    "        CSVLogger(\"model_details.csv\"),\n",
    "        EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edb16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=model.fit(\n",
    "        x1,y1,\n",
    "        epochs=50,\n",
    "        validation_data=(x2,y2),\n",
    "        batch_size=8,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the l2wbb2wwnnnwwoss\n",
    "plt.plot(r.history['loss'], label='Train loss')\n",
    "plt.plot(r.history['val_loss'], label='Val loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['acc'], label='Train acc')\n",
    "plt.plot(r.history['val_acc'], label='Val acc')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/MyDrive/DATA/high_acc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d70fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model\n",
    "# Choose a specific layer to extract features from\n",
    "desired_layer = base_model.get_layer('layer_normalization_24')\n",
    "feature_extractor_model = Model(inputs=base_model.input, outputs=desired_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a45e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "F=[]\n",
    "for i in tqdm(range(len(x2))):\n",
    "    image=x2[i].reshape([-1,784,192])\n",
    "    features=feature_extractor_model.predict(image)\n",
    "    F.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798d43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/content/drive/MyDrive/DATA/features_test_transformer.npy\",F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56874277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
